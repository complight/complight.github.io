# A year at a glance: Computational Light Laboratory bridges student potential into scientific success with industrial partners

_Written by [**Kaan Akşit**](https://kaanaksit.com), 1 December 2025_


## Learned Single-Pass Multitasking Perceptual Graphics for Immersive Displays
!!! example end "[**Learned Single-Pass Multitasking Perceptual Graphics for Immersive Displays**](../publications/multitasking_perceptual_graphics.md)"
    **Presented by:** [**Doğa Yılmaz**](https://yilmazdoga.net/), [He Wang](https://drhewang.com/), [Towaki Takikawa](https://tovacinni.github.io/), [Duygu Ceylan](https://www.duygu-ceylan.com/) and [Kaan Akşit](https://kaanaksit.com)

    **Location:** Dublin, Ireland

    **Time:** 4:30 pm - 6:00 pm, 31 October 2025

    **Session:** [**Regular Papers**](https://acmmm2025.org/accepted-regular-papers/)

[Doğa Yılmaz](https://yilmazdoga.net/) reached Kaan Akşit via email around mid-September in 2023, expressing his interest in becoming a research intern at the Computational Light Laboratory.
These early discussions between Kaan and Doğa have led to identifying Doğa's motivations in research and long-term plans involving obtaining a Ph.D. degree at reputable universities in the United Kingdom and Northern Ireland.
Specifically, Kaan and Doğa have agreed to collaborate on themes of perceptual graphics and deep learning methods aimed at applications such as virtual reality.
During Doğa's internship at the Computational Light Laboratory, he demonstrated persistent motivation and progress toward developing multitasking convolutional neural networks and perceptual graphics methods. His work involved studying human vision and exploring rendering techniques for immersive displays that cater to human observers in a highly realistic manner.
These studies included foveated rendering methods used in virtual reality headsets, chromastereopsis rendering for pseudo-3D effects on all display types, denoising techniques for improving image quality, and quantization methods for low-and-high dynamic images.


<figure markdown>
  ![Image title](../publications/media/multitasking_perceptual_graphics_teaser.png){ width="900" }
  <figcaption> Given RGB images and text-prompts, our model performs text-described perceptual tasks in a single inference step.</figcaption>
</figure>

A significant achievement during his internship was the development of a single deep learning model that could modify images according to text prompts. This enabled a unified approach for computer graphics applications across immersive displays such as virtual reality headsets, augmented reality glasses, and 3D desktop displays.
Doğa's well-established development and carefully written documentation led him to submit his work to the prestigious ACM Multimedia 2025 conference, which subsequently accepted it in their regular paper track. This accomplishment not only resulted in a high-tier publication but also provided solid evidence for his Ph.D. applications.
Currently, Doğa is a first-year Ph.D. student supervised by [Dr. He Wang](https://drhewang.com/) at the [University College London](https://www.ucl.ac.uk)'s computer science department.
Doğa's academic progress and achievements through his internship, as well as his success in publishing and securing a Ph.D. admission, demonstrate an exemplary success story for students aiming to enhance their academic profiles through hard work and persistence.


## Assessing Learned Methods for Hologram Compression
!!! example end "[**Assessing Learned Models for Phase-only Hologram Compression**](../publications/assess_hologram_compression.md)"
    **Presented by:** [**Zicong Peng**](https://scholar.google.com/citations?user=lpi8DvIAAAAJ&hl=zh-CN), [Yicheng Zhan](https://albertgary.github.io/), [Josef Spjut](https://josef.spjut.me/), and [Kaan Akşit](https://kaanaksit.com)

    **Location:** Convention Centre, Vancouver, BC, Canada

    **Time:** Monday-Thursday, 10-14 August 2025

    **Session:** [**Poster Track**](https://s2025.conference-schedule.org/presentation/?id=pos_195&sess=sess404)


[Zicong Peng](https://scholar.google.com/citations?user=lpi8DvIAAAAJ&hl=zh-CN) demonstrated exceptional motivation and outstanding implementation skills throughout his master’s thesis work.
Zicong dove into a topic entirely new to him: **"Deep Learning based Compression methods for Holographic Displays"**.
These displays are an emerging field with transformative potential for next-generation augmented reality glasses, virtual reality headsets, and desktop 3D displays.
Firstly, Zicong quickly mastered the replication of established hologram simulation algorithms involving light propagation techniques in free space, and learned to simulate holograms as if displayed using a holographic display.
Through a rigorous series of experiments, Zicong generated structured guidance on the performance of learned hologram compression algorithms.
In this context, Zicong is focused on Variational Autoencoder and Neural Implicit Representation structures.
Zicong's well prepared documentation and assessments formulated the basis of a submission to the prestigious **SIGGRAPH 2025 Poster Track**.


<figure markdown>
  ![](../publications/media/hologram_compression_represent_image.jpg){ width="700" }
  <figcaption>We evaluate the performance of four common learned models utilizing Implicit Neural Representation (INR) and Variational Autoencoder (VAE) structures for compressing phase-only holograms in holographic displays.</figcaption>
</figure>


Zicong further elevated the quality of his work by collaborating with industrial and academic partners, including [Josef Spjut](https://josef.spjut.me/) of NVIDIA, [Yicheng Zhan](https://albertgary.github.io/) of UCL and [Kaan Akşit](https://kaanaksit.com).
As of **10 August 2025**, Zicong Peng's work was accepted and presented at **[SIGGRAPH 2025](https://s2025.conference-schedule.org/presentation/?id=pos_195&sess=sess404)**.
Zicong’s journey serves as an exemplary model for beginners in any scientific field, proving that motivation, attentive mentorship, and active engagement with the collaborators can lead to remarkable success.
Throughout this process, he developed a robust technical skillset, a deep understanding of scientific methodology, and improved communication skills—opening doors to future Ph.D. studentship opportunities in [Koç University](https://ku.edu.tr) under the guidance of Professor [Hakan Urey](https://mysite.ku.edu.tr/hurey/).


## Implicit Neural Representations for Optical Raytracing
!!! example end "[**Efficient Proxy Raytracer for Optical Systems using Implicit Neural Representations**](https://github.com/shiasin/Efficient-Proxy-Raytracer-for-Optical-Systems-using-Implicit-Neural-Representations)"
    **Presented by:** [Shive Sinaei](https://www.xr.sys.es.osaka-u.ac.jp/en/team/), [**Chuanjun Zheng**](https://scholar.google.com.hk/citations?user=9Jk_LC8AAAAJ&), [Kaan Akşit](https://kaanaksit.com), and [Daisuke Iwai](https://daisukeiwai.org/).

    **Location:** Convention Centre, Vancouver, BC, Canada

    **Time:** Monday-Thursday, 10-14 August 2025

    **Session:** [**Poster Track**](https://s2025.conference-schedule.org/presentation/?id=pos_198&sess=sess406)

[**Chuanjun Zheng**](https://scholar.google.com.hk/citations?user=9Jk_LC8AAAAJ) concluded his remote internship in our laboratory, collaborating with external partners from the [University of Osaka](https://www.osaka-u.ac.jp/en).
During this collaboration, Chuanjun mentored first year Ph.D. student [Shiva Sinaei](https://www.xr.sys.es.osaka-u.ac.jp/en/team/) by sharing insights from his earlier experimtns on implicit neural representations.
Together, Chuanjun and Shiva identified an implicit neural representation capable of modeling optical lenses as a learned component.
Their work demonstrated that this learned lens representation could accurately raytrace optical beams for simple imaging tasks, an interesting starting point for a more complete investigation in the future.
As Chuanjun wraps up his internship, Chuanjun is set to begin a new chapter at the [University of Hawai'i at Mānoa](https://manoa.hawaii.edu/), where Chuanjun will work under the supervision of [Dr. Huaijin (George) Chen](https://hgchen.com/).


## Outreach
We host a Slack group with more than 250 members.
This Slack group focuses on the topics of rendering, perception, displays and cameras.
The group is open to public and you can become a member by following [this link](../outreach/index.md).


## Contact Us
!!! Warning
    Please reach us through [email](mailto:kaanaksit@kaanaksit.com) to provide your feedback and comments.
